# Estructura de Pruebas Automatizadas - ToyBotSolutions

## ğŸ“‹ DescripciÃ³n

Esta estructura de pruebas automatizadas estÃ¡ diseÃ±ada para ser **completamente independiente** del cÃ³digo fuente del proyecto. No modifica, sobrescribe ni elimina ningÃºn archivo existente creado por el equipo de desarrollo.

## ğŸ—ï¸ Estructura del Proyecto

```
testing/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ package.json                 # Dependencias de testing
â”œâ”€â”€ jest.config.js              # ConfiguraciÃ³n de Jest
â”œâ”€â”€ setup/
â”‚   â”œâ”€â”€ global-setup.js         # ConfiguraciÃ³n global de pruebas
â”‚   â””â”€â”€ test-database.js        # ConfiguraciÃ³n de base de datos de pruebas
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ hash.test.js        # Pruebas unitarias de utilidades
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ chatService.test.js # Pruebas unitarias de servicios
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ auth.integration.test.js  # Pruebas de integraciÃ³n de autenticaciÃ³n
â”‚       â””â”€â”€ chat.integration.test.js  # Pruebas de integraciÃ³n de chat
â”œâ”€â”€ e2e/
â”‚   â””â”€â”€ auth-flow.test.js       # Pruebas end-to-end de flujo de autenticaciÃ³n
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run-tests.sh            # Script para ejecutar todas las pruebas
â”œâ”€â”€ mocks/
â”‚   â”œâ”€â”€ openai.mock.js          # Mock de OpenAI API
â”‚   â””â”€â”€ database.mock.js        # Mock de base de datos
â””â”€â”€ reports/                    # Reportes de cobertura (generados automÃ¡ticamente)
```

## ğŸš€ InstalaciÃ³n

### Prerrequisitos
- Node.js 20+ 
- npm o yarn
- Acceso al cÃ³digo fuente del proyecto

### Pasos de InstalaciÃ³n

1. **Navegar a la carpeta de testing:**
   ```bash
   cd testing
   ```

2. **Instalar dependencias:**
   ```bash
   npm install
   ```

3. **Configurar variables de entorno:**
   ```bash
   cp .env.example .env
   # Editar .env con las configuraciones necesarias
   ```

## ğŸ§ª EjecuciÃ³n de Pruebas

### Ejecutar Todas las Pruebas
```bash
npm test
```

### Ejecutar Pruebas por Tipo
```bash
# Solo pruebas unitarias
npm run test:unit

# Solo pruebas de integraciÃ³n
npm run test:integration

# Solo pruebas E2E
npm run test:e2e

# Con cobertura
npm run test:coverage
```

### Ejecutar Pruebas EspecÃ­ficas
```bash
# Ejecutar un archivo especÃ­fico
npm test -- auth.test.js

# Ejecutar con watch mode
npm run test:watch
```

## ğŸ“Š Reportes de Cobertura

Los reportes de cobertura se generan automÃ¡ticamente en la carpeta `reports/`:

- **HTML**: `reports/coverage/index.html` - Reporte visual detallado
- **JSON**: `reports/coverage/coverage.json` - Datos estructurados
- **LCOV**: `reports/coverage/lcov.info` - Formato para CI/CD

### Ver Reporte HTML
```bash
# En Windows
start reports/coverage/index.html

# En macOS
open reports/coverage/index.html

# En Linux
xdg-open reports/coverage/index.html
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno
Crear archivo `.env` en la carpeta `testing/`:

```env
# ConfiguraciÃ³n del servidor
TEST_SERVER_PORT=3001
TEST_SERVER_HOST=localhost

# ConfiguraciÃ³n de base de datos
TEST_DB_PATH=./test-database.sqlite

# ConfiguraciÃ³n de JWT
TEST_JWT_SECRET=test-secret-key

# ConfiguraciÃ³n de OpenAI (para mocks)
OPENAI_API_KEY=test-key
```

### ConfiguraciÃ³n de Jest
El archivo `jest.config.js` estÃ¡ configurado para:
- Ejecutar pruebas en paralelo
- Generar reportes de cobertura
- Usar mocks automÃ¡ticamente
- Configurar timeouts apropiados

## ğŸ“ Agregar Nuevas Pruebas

### 1. Pruebas Unitarias
Crear archivo en `unit/[categoria]/[nombre].test.js`:

```javascript
const { functionToTest } = require('../../../backend/src/path/to/module');

describe('Nombre del MÃ³dulo', () => {
  test('deberÃ­a hacer algo especÃ­fico', () => {
    const result = functionToTest(input);
    expect(result).toBe(expectedOutput);
  });
});
```

### 2. Pruebas de IntegraciÃ³n
Crear archivo en `integration/[categoria]/[nombre].integration.test.js`:

```javascript
const request = require('supertest');
const { createTestServer } = require('../../setup/test-server');

describe('API Endpoint', () => {
  let server;

  beforeAll(async () => {
    server = await createTestServer();
  });

  afterAll(async () => {
    await server.close();
  });

  test('deberÃ­a responder correctamente', async () => {
    const response = await request(server)
      .post('/api/endpoint')
      .send({ data: 'test' });
    
    expect(response.status).toBe(200);
  });
});
```

### 3. Pruebas E2E
Crear archivo en `e2e/[nombre].test.js`:

```javascript
const { test, expect } = require('@playwright/test');

test('flujo completo de usuario', async ({ page }) => {
  await page.goto('http://localhost:5173');
  // ... pasos del flujo
  await expect(page.locator('.success')).toBeVisible();
});
```

## ğŸ”„ CI/CD Integration

### GitHub Actions
El archivo `.github/workflows/test.yml` estÃ¡ configurado para:

1. **Instalar dependencias** del proyecto y testing
2. **Ejecutar pruebas** en paralelo
3. **Generar reportes** de cobertura
4. **Subir reportes** como artifacts
5. **Notificar** resultados

### ConfiguraciÃ³n Local para CI/CD
```bash
# Ejecutar como en CI/CD
npm run test:ci
```

## ğŸ› SoluciÃ³n de Problemas

### Problemas Comunes

1. **Error de puerto ocupado:**
   ```bash
   # Cambiar puerto en .env
   TEST_SERVER_PORT=3002
   ```

2. **Error de base de datos:**
   ```bash
   # Limpiar base de datos de pruebas
   npm run test:clean-db
   ```

3. **Error de dependencias:**
   ```bash
   # Reinstalar dependencias
   rm -rf node_modules package-lock.json
   npm install
   ```

### Logs Detallados
```bash
# Ejecutar con logs verbosos
npm test -- --verbose
```

## ğŸ“š Buenas PrÃ¡cticas

### Nomenclatura
- **Archivos de prueba**: `[nombre].test.js` o `[nombre].spec.js`
- **Describe blocks**: Usar nombres descriptivos en espaÃ±ol
- **Test cases**: Usar formato "deberÃ­a [acciÃ³n] cuando [condiciÃ³n]"

### Estructura de Pruebas
```javascript
describe('Nombre del MÃ³dulo', () => {
  // Setup
  beforeEach(() => {
    // PreparaciÃ³n antes de cada prueba
  });

  // Teardown
  afterEach(() => {
    // Limpieza despuÃ©s de cada prueba
  });

  // Casos de prueba
  describe('cuando [condiciÃ³n]', () => {
    test('deberÃ­a [resultado esperado]', () => {
      // ImplementaciÃ³n
    });
  });
});
```

### Mocks y Stubs
- Usar mocks para dependencias externas
- Crear stubs para funciones complejas
- Mantener mocks en la carpeta `mocks/`

## ğŸ¤ ContribuciÃ³n

Para agregar nuevas funcionalidades de testing:

1. Crear rama desde `main`
2. Implementar cambios en carpeta `testing/`
3. Agregar pruebas para nuevas funcionalidades
4. Verificar que todas las pruebas pasen
5. Crear Pull Request

## ğŸ“ Soporte

Para problemas o preguntas sobre la estructura de pruebas:

1. Revisar este README
2. Verificar logs de errores
3. Consultar documentaciÃ³n de Jest y Supertest
4. Crear issue en el repositorio

---

**Nota**: Esta estructura estÃ¡ diseÃ±ada para ser portable y puede ser copiada a cualquier release del proyecto sin modificar el cÃ³digo fuente. 